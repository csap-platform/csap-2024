#
# Full csap reference cluster, including csap-events, clustered kubernetes
#
# Update:
#   $managerHost - k8s master, csap-admin
#   $workerHosts - k8s master, csap-admin
#   $hostDomain -  hostDomain
#   $appName - name of application
#   $apiToken - rest apis betweem csap-agents - csap-admin - csap events
#   $appId - used for event and project ids (lowercase hyphenated)
#   $envId - used for event and project ids (lowercase hyphenated)
#
#



operator: modify
target: default


environments:

  base: dev     # source: derived from "default" application, which defines a "dev" environment
  name: $envId  # optional name of target env; defaults to the base env if not specified
  #
  # Cluster host assignment:
  #   - use host short name
  #   - optional: specify short name everywhere; or use index of hostname from base-os cluster
  #                
  hosts: 
  
    base-os: [ $managerHost, $workerHosts ]
    csap-management: [ 1 ]
    perf-system: [ $managerHost, $workerHosts ]
    perf-java: [ $managerHost, $workerHosts ]
    perf-mysql: [ $managerHost, $workerHosts ]
    dcib-services:  [ 1 ]
    kubernetes-masters:  [ 1 ]
    kubernetes-provider: [ $managerHost, $workerHosts ]
  

  application-name: "$appName"
  project-name: "$appId"
  project-contact: "xxx.xxx@$hostDomain"
  
  git: https://github.com/xxx/xxx-definition.git


  #
  # update target env
  #
  settings:

    loadbalancer-url-orig: http://$managerHost.$hostDomain:8080
    loadbalancer-url: http://$managerHost.$hostDomain:8021/csap-admin

    application:
      host-settings:
        private-to-public:
          ip-10-0-1-103: ec2-11-22-33-44.us-west-2.compute.amazonaws.com
          ip-10-0-1-199: ec2-11-22-33-55.us-west-2.compute.amazonaws.com
          ip-10-0-1-157: ec2-11-22-33-66.us-west-2.compute.amazonaws.com

        tags:
          default: x86
          ip-10-0-1-26: inst
          ip-10-0-1-103: master
          ip-10-0-1-218: arm
          ip-172-31-60-242: arm
          ip-172-31-49-202: r5a
          ip-172-31-8-222: r5b
          ip-172-31-48-212: r5

    
    # Enable NFS Support using nfs container created below
    configuration-maps:
      docker:
        allowRemote: true



      perf-java-settings:
        reportName: java-defaults-2users-5min
        reportName-zing: zing22-java8-4users-1burn-1ms-60min
        reportName-open: open-java17-4users-1burn-0ms-60min
        testToRun: default
        testToRunMaxUsers: default
        testToRunMinUsers: 6jvm-port
        warmUpMinutes: 0
        runMinutes: 5
        rampSeconds: 120
        queryThreads: 2
        queryThreadsAbout: "2 thread and 5ms delay for 4 core k8 host. 4 thread and 0ms delay for 8 core host. 12 threads with 0ms delay can busy out 100+ core hosts"
        queryDelayMs: 5
        purgeDbThreads: 1
        purgeDbThreadsAbout: "Use 6 for big hosts"
        purgeDelayMs: 100
        purgeDelayMs-fast: 100
        purgeDelayMs-heap: 60000
        burnThreads: 1
        burnThreads-about: "Use 12 for big hosts"
        burnDelayMs: 10000

      storage-settings-nfs:
        about-type: "vsphere or nfs can be used"
        $$storage-type: nfs
        $$storage-class: csap-nfs-storage-1
        $$storage-folder: csap-dev-platform-storage
        $$vsphere-datastore: YOUR_DS_NAME
        $$nfs-server: $managerHost.$hostDomain
        # note docker image maps nfsshare to / on the export 
        $$nfs-path: /
        $$nfs-options: "vers=4"
        $$nfs-mount: "/mnt/nfsshare"
        $$nfs-provisioner: kubernetes-pvcs-csap-platform
        #httpdDocFolder: $$nfs-mount/csap-web-server
    
  default-settings:  # defaults for ALL envs
  
    application:
      
      name: "$appName"
      
      quick-launches:
        - label: 'kubernetes: dashboard'
          service: kubernetes-dashboard
        - label: 'kubernetes: grafana'
          service: grafana
        - label: 'kubernetes: alertmanager'
          service: alertmanager
        - label: 'kubernetes: prometheus'
          service: prometheus
        - label: 'PERF: sysbench cpu'
          service: sysbench-cpu
        - label: 'PERF: sysbench memory'
          service: sysbench-memory
        - label: 'PERF: sysbench mysql'
          service: sysbench-mysql
        - label: 'PERF: mysql db'
          service: oss-mysql-db
        - label: 'PERF: mysql admin'
          service: oss-mysql-admin
        - label: 'PERF: fio tests'
          service: fio
        - label: 'PERF: Tomcat tests'
          service: perf-java-1

      help-menu:
        CompanyXXX CSAP: https://confluence.yourcompany.com/display/~peter.nightingale/WCSAP
  
    csap-data:
      user: "$apiToken"    # $appId events-disabled
      # user: xxx-myapp
      credential: "$apiToken"
      service-url-orig: "http://$managerHost.$hostDomain:8080/events-service"
      service-url: "http://$elasticIp:7021/events-service"
      

    configuration-maps:

    
#      docker:
#        dockerRepo: http://media.$hostDomain/media/third_party/linux/CentOS/docker-ce.repo
#        
#      kubelet:
#        kubernetesRepo: http://media.$hostDomain/media/third_party/kubernetes/kubernetes-el7.repo
        
      ingress-nginx:
        $$ingress-host: "*.$hostDomain" # used to determine ingress launch urls and routing rules
        $$ingress-node-selector: "\"kubernetes.io/os\": linux"
        $$ingress-http-port: 7080
        $$ingress-https-port: 7443
          
        
      csap-events-defaults: 
        # mongoUserNeeded: ForImageAndBoot
        mongoUser: dataBaseReadWriteUser
        mongoPassword: "$apiToken"
        mongoHosts: "$$csap-hosts:events-mongo"
        $$mongo-storage: "/opt/csap/$$service-name-volume"
        # $$mongo-storage: "$$nfs-mount/$$nfs-sub-folder/$$service-name-volume"
        # dataServiceUrl "http://csap-dev01.$hostDomain:8080/events-service/api/event"
        restToken: "$apiToken"
        dataServiceUser: "$appId"
        dataServicePass: "$apiToken"
        metricDbSizeInGb: 5
        eventDbSizeInGb: 1
        MONGO_UTIL: "csapplatform/mongo:21.08"
        MONGO_INITDB_ROOT_USERNAME: dataBaseReadWriteUser
        MONGO_INITDB_ROOT_PASSWORD: "$apiToken"
        #MONGO_INITDB_ROOT_PASSWORD: "doDecode:ikS+e8JgH07FPqGIprwwawHHId9i4+K2"
      mysql-nft-settings:
        $$db-host: oss-mysql-db
        $$db-pass: nyw
        about-test: Settings for sysbench
        xminutesToRun: 1
        xtestProfile: default
        xtestProfile-options: default, oltp, csapOltp
        found-in:
          - oss-mysql-admin
          - oss-mysql-db
          - sysbench-mysql


  #
  # adding in csap-management and kubernetes
  #
  clusters: 
  
    #
    # csap-admin provide core cluster management
    #
    csap-management: 
      notes: "For production clusters, 2 hosts are recommended. All others - a single host is sufficient"
      type: modjk
      hosts:
        - updated-above-in-hosts
      template-references: 
        - csap-admin
        
    #
    # performance tests
    #
    perf-java:
      type: simple
      enabled: true
      hosts:
        - updated-above-in-hosts
      template-references:
        - perf-java-1
        - perf-java-jmeter

    perf-mysql:
      type: simple
      enabled: true
      hosts:
        - updated-above-in-hosts
      template-references:
        - oss-mysql-admin
        - oss-mysql-db
        - sysbench-mysql

    perf-system:
      type: simple
      enabled: true
      hosts:
        - updated-above-in-hosts
      template-references:
        - fio
        - sysbench-cpu
        - sysbench-memory
    #
    # enterprise placeholders to verify nfs, ldap
    #
    dcib-services:
      type: simple
      enabled: false
      hosts:
        - updated-above-in-hosts
      template-references:
        - nfs-server


    #
    # singe master clusters are ok for non-prod; generally 3 nodes
    #  
    kubernetes-provider:
      type: kubernetes-provider
      enabled: false
      masters:
        - updated-above-in-hosts
      hosts:
        - updated-above-in-hosts
      template-references: 
        - kubelet
    
    kubernetes-system-services:
      type: kubernetes
      enabled: false
      kubernetes-provider: kubernetes-provider
      kubernetes-namespace: kube-system
      template-references: 
        - calico-kube-controllers
        - calico-node
        - coredns
        - etcd
        - kube-apiserver
        - kube-controller-manager
        - kube-proxy
        - kube-scheduler
        - kubernetes-dashboard
        - metrics-server
        - ingress-nginx
        # Note: only enable client provisioner if nfs configured
        - nfs-client-provisioner



operations: 
  - inserts:
    - path: /environments/defaults/base-os/template-references
      value: docker

service-templates:

  csap-demo-nginx.docker.image: "nginx:latest"



      


---
#
# Core csap settings: demo-xxx Morrisville Security(LDAP)
#
operator: create
target: application-company.yml

#
# Global settings for applications - test
#



     
csap-core:

  kubernetes: 
    enabled: true

  docker: 
    enabled: true
    

#
# health and data services
#
#csap-events: 
#
#  health-monitoring: 
#    appIds:
#      - xxx
#    lifes:
#      - dev


#spring: 
#  mail: 
#    host: "${mailServer:myrelay.demo-xxx.com}"
#    port: "${mailPort:25}"

csap.security: 
    rest-api-filter.token: "$apiToken"
    provider-not-used:
            
      type: memory
      memory-users:
      - admin,password,AUTHENTICATED,dummy1,dummy2
      - user,password,AUTHENTICATED,dummy3,dummy4
      
      #
      # LDAP: https://github.com/csap-platform/csap-core/wiki/Access-Control
      #
      
        #
        #  docker caspplatform/csap:ldap ,https://github.com/bitnami/bitnami-docker-openldap
        #
        #  test openldap: docker run --rm --detach --name=ldap-server --publish 389:1389 csapplatform/ldap-server
        #  web user: admin/admin
        #  
        #  test ldap browser: docker run --rm --detach --name=ldap-ui --publish 8080:80 --env PHPLDAPADMIN_LDAP_HOSTS=$(hostname --long)  --env PHPLDAPADMIN_HTTPS=false osixia/phpldapadmin:latest
        #  ldap admin: cn=admin,dc=example,dc=org, pass: admin
        #

    #
    steps-to-enable:
       - verifying ldap server is up using ldapui
       - rename this to provider to provider-not-used
       - rename  provider-not-used to provider
       - save and activate the changes
       - restart admin and verify new ldap is being used
    
    #
    provider:
       type: ldap
       url: ldap://$elasticIp:7389
       directory-dn: search:uid={0}
       search-user: ou=people,dc=example,dc=org
       search-groups: ou=groups,dc=example,dc=org
       search-group-filter: "(uniquemember={0})"
      
      
      #
      # typical ldap
      #
#      type: ldap 
#      url: ldap://ldap.yourcompany.lab:389
#      directory-dn: search:uid={0} # search will be a search binding. If omitted - binds direct
#      search-user: ou=People,dc=yourdc,dc=net
#      search-groups: ou=Groups,dc=yourdc,dc=net
#
# Typically - LDAP/AD groups are used for group management
# - alternately, roles can be explictly assigned 
#
#      additional-ldap-roles:
#        pnightingale:
#          - ${view_role:AUTHENTICATED}
#          - ${admin_role:AUTHENTICATED}
#          - ${build_role:AUTHENTICATED}
#          - ${infra_role:AUTHENTICATED}




#---
#
# Sample: Creating a file, path is relative to csap-platfrom/definition
#
#operator: create
#target: scripts/hi.sh
#
#content: |
#  #!/bin/bash
#  echo "hi"


#---
##
##  Docker Repository
##
#operator: create
#
#target: resources/docker/common/configuration/daemon.json
#
#exec-opts: ["native.cgroupdriver=systemd"]
#  
#registry-mirrors: ["http://docker.$hostDomain"]
#insecure-registries: [ "demo-xxx-docker.$hostDomain", "docker.$hostDomain" ]
#storage-driver: "overlay2"
#data-root: "/var/lib/docker"
#hosts: [ "unix:///var/run/docker.sock" ]
#log-driver: "json-file"
#log-opts: 
#  max-size: "44m"
#  max-file: "1"

